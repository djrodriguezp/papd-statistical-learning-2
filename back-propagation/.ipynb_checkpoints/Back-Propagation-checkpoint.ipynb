{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back-Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkXOR:\n",
    "    def __init__(self,X,Y):\n",
    "        self.hidden_layers = []\n",
    "        self.input_nodes = X.shape[1]\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.output_layer = np.random.normal(0, 0.1, Y.shape) \n",
    "        \n",
    "    def __relu(self,x):\n",
    "        return x * (x > 0)\n",
    "\n",
    "    def __derivative_relu(self,x):\n",
    "        return 1 * (x >= 0)\n",
    "    \n",
    "    def add_layer(self,nodes):\n",
    "        if len(self.hidden_layers) == 0:\n",
    "            input_nodes = self.input_nodes + 1 #Agregamos un nodo adicional para el bias\n",
    "        \n",
    "        else:\n",
    "            input_nodes = self.hidden_layers[-1].shape[1] + 1 #Agregamos un nodo adicional para el bias\n",
    "        np_nodes =  np.random.normal(0, 0.1, (input_nodes)*nodes) \n",
    "        self.hidden_layers.append(np_nodes.reshape(-1,nodes))\n",
    "    \n",
    "    def forward_propagation(self):\n",
    "        input_values = np.c_[ self.X, np.ones(self.X.shape[0]) ]\n",
    "        for weights in self.hidden_layers:\n",
    "            output_values = self.__relu(np.matmul(input_values,weights))\n",
    "            input_values = np.c_[ output_values, np.ones(output_values.shape[0]) ]\n",
    "        y_aprox = np.matmul(input_values,self.output_layer)\n",
    "        return y_aprox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.16000689 0.13797661]\n",
      " [0.3537258  0.20936114]\n",
      " [0.00888533 0.18284511]\n",
      " [0.20260423 0.25422964]]\n",
      "[[ 0.10610984 -0.         -0.        ]\n",
      " [ 0.11866975 -0.         -0.        ]\n",
      " [ 0.10588601 -0.         -0.        ]\n",
      " [ 0.11844592 -0.         -0.        ]]\n",
      "[0.1614294  0.16059615 0.16144425 0.160611  ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.1614294 , 0.16059615, 0.16144425, 0.160611  ])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Posibles puntos del dominio XOR\n",
    "\n",
    "x1 = np.array([0,0,1,1]).reshape(-1,1)\n",
    "x2 =  np.array([0,1,0,1]).reshape(-1,1)\n",
    "X = np.hstack((x1,x2))\n",
    "Y = np.array([0,1,1,0])\n",
    "\n",
    "neural_network = NeuralNetworkXOR(X,Y)\n",
    "neural_network.add_layer(nodes=2)\n",
    "neural_network.add_layer(nodes=3)\n",
    "neural_network.hidden_layers\n",
    "neural_network.forward_propagation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
